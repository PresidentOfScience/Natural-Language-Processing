{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = []\n",
    "corpora.append(\"Kaggle allows user to find and publish data sets, explore and build models in a web-based data-science environment, work with other data scientists and machine learning engineers, and enter competitions to solve data science challenge.\")\n",
    "corpora.append(\"GeeksforGeeks is a provide a variety of services to help programmers to learn many programming languages easily. It contains well written, well thought and well explained computer science and programming articles.\")\n",
    "corpora.append(\"Stack Overflow is a question and answer website for professional and enthusiast programmers. It features as a forum on a wide range of topics in computer programming especially to help programmers solve problem and debug their program.\")\n",
    "corpora.append(\"W3Schools is a optimized for learning, testing, and training especially in web development field. User can try to live code and see the result while learning.\")\n",
    "corpora.append(\"GitHub is a internet hosting service for software development and version control. It provides the distributed version control including access control bug tracking, software feature requests, task management, and others. Work together easily.\")\n",
    "corpora.append(\"Netlify is a remote-first cloud computing company that offers a development platform that includes build, deploy, and serverless backend services for web applications and dynamic websites.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pretty dry, but I was able to pass with just t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>would be a better experience if the video and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Information was perfect! The program itself wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A few grammatical mistakes on test made me do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excellent course and the training provided was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8334</th>\n",
       "      <td>i cant even understand a single topic, not exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8335</th>\n",
       "      <td>the quiz for week 2 might change what i though...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8336</th>\n",
       "      <td>This course was extremely difficult for me.The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8337</th>\n",
       "      <td>Teaching is to technical I wish they made it m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8338</th>\n",
       "      <td>i dont like the testing screens. They are too ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8339 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "0     Pretty dry, but I was able to pass with just t...\n",
       "1     would be a better experience if the video and ...\n",
       "2     Information was perfect! The program itself wa...\n",
       "3     A few grammatical mistakes on test made me do ...\n",
       "4     Excellent course and the training provided was...\n",
       "...                                                 ...\n",
       "8334  i cant even understand a single topic, not exp...\n",
       "8335  the quiz for week 2 might change what i though...\n",
       "8336  This course was extremely difficult for me.The...\n",
       "8337  Teaching is to technical I wish they made it m...\n",
       "8338  i dont like the testing screens. They are too ...\n",
       "\n",
       "[8339 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('data.txt', sep=\"\\t\", header=None)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>positive</td>\n",
       "      <td>@united thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united by the time I finally get to Dallas I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united I'm trying to get to my final destinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>negative</td>\n",
       "      <td>@united that guy really has no customer servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>positive</td>\n",
       "      <td>@united he has no priority and Iove it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    airline_sentiment                                               text\n",
       "0            positive                @VirginAmerica What @dhepburn said.\n",
       "1            positive  @VirginAmerica plus you've added commercials t...\n",
       "2            positive  @VirginAmerica I didn't today... Must mean I n...\n",
       "3            negative  @VirginAmerica it's really aggressive to blast...\n",
       "4            negative  @VirginAmerica and it's a really big bad thing...\n",
       "..                ...                                                ...\n",
       "994          positive                                  @united thank you\n",
       "995          negative  @united by the time I finally get to Dallas I ...\n",
       "996          negative  @united I'm trying to get to my final destinat...\n",
       "997          negative  @united that guy really has no customer servic...\n",
       "998          positive             @united he has no priority and Iove it\n",
       "\n",
       "[999 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('data.csv')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    @VirginAmerica What @dhepburn said.\n",
       "1      @VirginAmerica plus you've added commercials t...\n",
       "2      @VirginAmerica I didn't today... Must mean I n...\n",
       "3      @VirginAmerica it's really aggressive to blast...\n",
       "4      @VirginAmerica and it's a really big bad thing...\n",
       "                             ...                        \n",
       "994                                    @united thank you\n",
       "995    @united by the time I finally get to Dallas I ...\n",
       "996    @united I'm trying to get to my final destinat...\n",
       "997    @united that guy really has no customer servic...\n",
       "998               @united he has no priority and Iove it\n",
       "Name: text, Length: 999, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>positive</td>\n",
       "      <td>@united thanks! It's 35K miles from RTB to Eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>positive</td>\n",
       "      <td>@united done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>positive</td>\n",
       "      <td>@united Thank you, ^JH, appreciate the prompt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>positive</td>\n",
       "      <td>@united thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>positive</td>\n",
       "      <td>@united he has no priority and Iove it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>485 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    airline_sentiment                                               text\n",
       "0            positive                @VirginAmerica What @dhepburn said.\n",
       "1            positive  @VirginAmerica plus you've added commercials t...\n",
       "2            positive  @VirginAmerica I didn't today... Must mean I n...\n",
       "6            positive  @VirginAmerica yes, nearly every time I fly VX...\n",
       "7            positive  @VirginAmerica Really missed a prime opportuni...\n",
       "..                ...                                                ...\n",
       "968          positive  @united thanks! It's 35K miles from RTB to Eur...\n",
       "988          positive                                       @united done\n",
       "989          positive  @united Thank you, ^JH, appreciate the prompt ...\n",
       "994          positive                                  @united thank you\n",
       "998          positive             @united he has no priority and Iove it\n",
       "\n",
       "[485 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df = dataframe[dataframe['airline_sentiment'] == 'positive']\n",
    "positive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kaggle', 'allows', 'user', 'to', 'find', 'and', 'publish', 'data', 'sets', ',', 'explore', 'and', 'build', 'models', 'in', 'a', 'web-based', 'data-science', 'environment', ',', 'work', 'with', 'other', 'data', 'scientists', 'and', 'machine', 'learning', 'engineers', ',', 'and', 'enter', 'competitions', 'to', 'solve', 'data', 'science', 'challenge', '.']\n",
      "['GeeksforGeeks', 'is', 'a', 'provide', 'a', 'variety', 'of', 'services', 'to', 'help', 'programmers', 'to', 'learn', 'many', 'programming', 'languages', 'easily', '.', 'It', 'contains', 'well', 'written', ',', 'well', 'thought', 'and', 'well', 'explained', 'computer', 'science', 'and', 'programming', 'articles', '.']\n",
      "['Stack', 'Overflow', 'is', 'a', 'question', 'and', 'answer', 'website', 'for', 'professional', 'and', 'enthusiast', 'programmers', '.', 'It', 'features', 'as', 'a', 'forum', 'on', 'a', 'wide', 'range', 'of', 'topics', 'in', 'computer', 'programming', 'especially', 'to', 'help', 'programmers', 'solve', 'problem', 'and', 'debug', 'their', 'program', '.']\n",
      "['W3Schools', 'is', 'a', 'optimized', 'for', 'learning', ',', 'testing', ',', 'and', 'training', 'especially', 'in', 'web', 'development', 'field', '.', 'User', 'can', 'try', 'to', 'live', 'code', 'and', 'see', 'the', 'result', 'while', 'learning', '.']\n",
      "['GitHub', 'is', 'a', 'internet', 'hosting', 'service', 'for', 'software', 'development', 'and', 'version', 'control', '.', 'It', 'provides', 'the', 'distributed', 'version', 'control', 'including', 'access', 'control', 'bug', 'tracking', ',', 'software', 'feature', 'requests', ',', 'task', 'management', ',', 'and', 'others', '.', 'Work', 'together', 'easily', '.']\n",
      "['Netlify', 'is', 'a', 'remote-first', 'cloud', 'computing', 'company', 'that', 'offers', 'a', 'development', 'platform', 'that', 'includes', 'build', ',', 'deploy', ',', 'and', 'serverless', 'backend', 'services', 'for', 'web', 'applications', 'and', 'dynamic', 'websites', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "for corpus in corpora:\n",
    "    tokenized = word_tokenize(corpus)\n",
    "    print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "paragraph = \"Natural Language Programming (NLP) refers to the field of computer science that focuses on enabling computers to understand and process human language in a way that is similar to how humans do. NLP involves developing algorithms and techniques that allow computers to interpret and analyze text or speech data, enabling them to perform tasks such as language translation, sentiment analysis, and question answering. By leveraging machine learning and artificial intelligence, NLP aims to bridge the gap between human language and computer understanding, opening up possibilities for more intuitive and efficient human-computer interactions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural Language Programming (NLP) refers to the field of computer science that focuses on enabling computers to understand and process human language in a way that is similar to how humans do.',\n",
       " 'NLP involves developing algorithms and techniques that allow computers to interpret and analyze text or speech data, enabling them to perform tasks such as language translation, sentiment analysis, and question answering.',\n",
       " 'By leveraging machine learning and artificial intelligence, NLP aims to bridge the gap between human language and computer understanding, opening up possibilities for more intuitive and efficient human-computer interactions.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_list = sent_tokenize(paragraph)\n",
    "sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Programming',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'field',\n",
       " 'of',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'that',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'enabling',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'and',\n",
       " 'process',\n",
       " 'human',\n",
       " 'language',\n",
       " 'in',\n",
       " 'a',\n",
       " 'way',\n",
       " 'that',\n",
       " 'is',\n",
       " 'similar',\n",
       " 'to',\n",
       " 'how',\n",
       " 'humans',\n",
       " 'do',\n",
       " '.',\n",
       " 'NLP',\n",
       " 'involves',\n",
       " 'developing',\n",
       " 'algorithms',\n",
       " 'and',\n",
       " 'techniques',\n",
       " 'that',\n",
       " 'allow',\n",
       " 'computers',\n",
       " 'to',\n",
       " 'interpret',\n",
       " 'and',\n",
       " 'analyze',\n",
       " 'text',\n",
       " 'or',\n",
       " 'speech',\n",
       " 'data',\n",
       " ',',\n",
       " 'enabling',\n",
       " 'them',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'tasks',\n",
       " 'such',\n",
       " 'as',\n",
       " 'language',\n",
       " 'translation',\n",
       " ',',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'and',\n",
       " 'question',\n",
       " 'answering',\n",
       " '.',\n",
       " 'By',\n",
       " 'leveraging',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'artificial',\n",
       " 'intelligence',\n",
       " ',',\n",
       " 'NLP',\n",
       " 'aims',\n",
       " 'to',\n",
       " 'bridge',\n",
       " 'the',\n",
       " 'gap',\n",
       " 'between',\n",
       " 'human',\n",
       " 'language',\n",
       " 'and',\n",
       " 'computer',\n",
       " 'understanding',\n",
       " ',',\n",
       " 'opening',\n",
       " 'up',\n",
       " 'possibilities',\n",
       " 'for',\n",
       " 'more',\n",
       " 'intuitive',\n",
       " 'and',\n",
       " 'efficient',\n",
       " 'human-computer',\n",
       " 'interactions',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = word_tokenize(paragraph)\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'Language', 'Programming', 'NLP', 'refers', 'field', 'computer', 'science', 'focuses', 'enabling', 'computers', 'understand', 'process', 'human', 'language', 'way', 'similar', 'humans']\n",
      "['NLP', 'involves', 'developing', 'algorithms', 'techniques', 'allow', 'computers', 'interpret', 'analyze', 'text', 'speech', 'data', 'enabling', 'perform', 'tasks', 'language', 'translation', 'sentiment', 'analysis', 'question', 'answering']\n",
      "['leveraging', 'machine', 'learning', 'artificial', 'intelligence', 'NLP', 'aims', 'bridge', 'gap', 'human', 'language', 'computer', 'understanding', 'opening', 'possibilities', 'intuitive', 'efficient', 'human-computer', 'interactions']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "eng_stopwords = stopwords.words('english')\n",
    "# eng_stopwords.append('By')\n",
    "\n",
    "for sentence in sentence_list:\n",
    "    tokenized = word_tokenize(sentence)\n",
    "\n",
    "    # for token in tokenized:\n",
    "    #     if token in string.punctuation:\n",
    "    #         tokenized.remove(token)\n",
    "    \n",
    "    tokenized = [token for token in tokenized if token not in string.punctuation]\n",
    "    tokenized = [token for token in tokenized if token.lower() not in eng_stopwords]\n",
    "    \n",
    "    print(tokenized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "natural_language_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
